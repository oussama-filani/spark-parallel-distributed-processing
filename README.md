# ğŸš€ Traitement parallÃ¨le et distribuÃ© avec Apache Spark

Ce projet dÃ©montre le traitement **parallÃ¨le** et **distribuÃ©** de donnÃ©es de ventes avec **Apache Spark** en utilisant Java. L'application est testÃ©e localement puis dÃ©ployÃ©e sur un **cluster Docker**.

---

## ğŸ“‹ Description du Projet

### **Exercice 1 : Total des ventes par ville**
DÃ©veloppement d'une application Spark qui analyse un fichier `ventes.txt` pour calculer :
- Le **total des ventes par ville**

### **Exercice 2 : Total des ventes par ville et annÃ©e**
Extension de l'application pour calculer :
- Le **total des ventes par ville et par annÃ©e**

**Format du fichier d'entrÃ©e :**
```
date,ville,produit,prix
2025-01-01,Rabat,Ordinateur,7000.0
2025-01-01,Marrakech,Imprimante,3000.0
2025-01-01,Fes,Ecran,1500.0
```

---

## ğŸ“ Structure du Projet

```
spark-parallel-distributed-processing/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/
â”‚       â””â”€â”€ java/
â”‚           â””â”€â”€ net/
â”‚               â””â”€â”€ oussama/
â”‚                   â”œâ”€â”€ App1.java        # Total des ventes par ville
â”‚                   â”œâ”€â”€ App2.java        # Total des ventes par ville et annÃ©e
â”‚                   â””â”€â”€ Main.java        # Application combinÃ©e
â”œâ”€â”€ ventes.txt                          # DonnÃ©es de ventes
â”œâ”€â”€ pom.xml                             # Configuration Maven
â””â”€â”€ target/
    â””â”€â”€ spark-parallel-distributed-processing-1.0-SNAPSHOT-jar-with-dependencies.jar
```

---

## âš™ï¸ Technologies UtilisÃ©es

- **Java 11**
- **Apache Spark 3.5.5**
- **Maven 3.8+**
- **Docker & Docker Compose**
- **Bitnami Spark Docker image**

---

## ğŸ› ï¸ Configuration et Compilation

### Configuration Maven (pom.xml)
```xml
<properties>
    <maven.compiler.source>11</maven.compiler.source>
    <maven.compiler.target>11</maven.compiler.target>
    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
</properties>
```

### Compilation
```bash
mvn clean package
```

---

## ğŸš€ ExÃ©cution Locale

### Application 1 : Classement des prix total des ventes par ville
```bash
spark-submit --class net.oussama.App1 --master spark://spark-master:7077 spark-parallel-distributed-processing-1.0-SNAPSHOT-jar-with-dependencies.jar
```

![Application 1 - Total par ville](images/app1.png)

### Application 2 : Classement des prix total des ventes par ville et annÃ©e
```bash
spark-submit --class net.oussama.App2 --master spark://spark-master:7077 spark-parallel-distributed-processing-1.0-SNAPSHOT-jar-with-dependencies.jar
```

![Application 2 - Total par ville et annÃ©e](images/app2.png)

---

## DÃ©ploiement sur Cluster Spark


### 1. DÃ©marrage du cluster
```bash
docker-compose up -d
```

Interface Web Spark : [http://localhost:8080](http://localhost:8080)

### 3. Copie des fichiers dans le conteneur
```bash
docker cp ./spark-parallel-distributed-processing-1.0-SNAPSHOT-jar-with-dependencies.jar spark-master:/opt/bitnami/spark
docker cp ./spark-parallel-distributed-processing-1.0-SNAPSHOT-jar-with-dependencies.jar spark-worker-1:/opt/bitnami/spark

docker cp ./ventes.txt spark-master:/opt/bitnami/spark
```

### 4. ExÃ©cution sur le cluster
```bash
docker exec -it spark-master bash
cd /opt/bitnami/spark

# ExÃ©cution de l'application principale
spark-submit --class net.oussama.Main --master spark://spark-master:7077 spark-parallel-distributed-processing-1.0-SNAPSHOT-jar-with-dependencies.jar
```

---

## RÃ©sultats dans le Cluster Spark

### ExÃ©cution des calculs de ventes par ville et annÃ©e
![RÃ©sultats sur le cluster](images/main-app.png)

---

## ğŸ’¡ Conclusion

Ce projet dÃ©montre la puissance d'Apache Spark pour le traitement parallÃ¨le et distribuÃ© de donnÃ©es. Ã€ travers ces applications, nous avons illustrÃ© :

1. **La simplicitÃ© de dÃ©veloppement** : Spark permet d'implÃ©menter des analyses complexes avec peu de code
2. **La scalabilitÃ©** : La mÃªme application fonctionne localement et sur un cluster distribuÃ©
3. **La flexibilitÃ©** : Les transformations RDD permettent diverses analyses sur les mÃªmes donnÃ©es
